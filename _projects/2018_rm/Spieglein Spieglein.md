---
identifier: 97
layout: project
year: Rhein-Main 2018
isFirst: false
isLast: false
"name": "Spieglein, Spieglein"
"tile": "/img/projekte-tiles/2018_rm/spieglein.png"
"tile_active": "/img/projekte-tiles/2018_rm/spieglein-active.png"
"image": "/img/projekte/spieglein.png"
"links":
    -
        "class": "website"
        "link": "https://spiegleinspieglein.github.io/"
        "text": "Augmented-Reality-App"
    -
        "class": "github"
        "link": "https://github.com/SpiegleinSpieglein/SpiegleinSpieglein"
        "text": "GitHub"
"data":
    - "Historisches Museum Frankfurt"
    - "Kleid durch Photogrammetrie als 3D-Objekt von Torsten Hemke"
"team":
    -
        "name": "Daniel-Amadeus Johannes Glöckner"
        "contact":
            "mail": "mailto:daniel-amadeus.gloeckner@student.hpi.de"
    -
        "name": "Fabian Moritz Schneider"
        "contact":
            "mail": "mailto:moritz.schneider@uni-potsdam.de"
    -
        "name": "Lukas Wagner"
        "contact":
            "mail": "mailto:lukas.wagner@student.hpi.de"
    -
        "name": "Lisa Ihde"
        "contact":
            "mail": "mailto:lisa.ihde@student.hpi.de"
    -
        "name": "Jonas Bounama"
        "contact":
            "mail": "mailto:jonas.bounama@student.hpi.de"
    -
        "name": "Joana Bergsiek"
        "contact":
            "mail": "mailto:joana.bergsiek@student.hpi.de"
---

„Spieglein, Spieglein“ verwendet 3D-Scans der Kleider des Historischen Museums Frankfurt. 

Diese wurden von dem Projekt „Das bewegte Kleid“ photogrammetrisch aufgenommen und uns zur Verfügung gestellt. Die originalen Kleider aus dem Projekt „Kleider in Bewegung“ des Museums können verständlicherweise von Besuchern nicht getragen werden. Damit sind sie leider nicht in Bewegung, sondern nur hinter Glasscheiben betrachtbar. 

Das ändern wir mit unserer Anwendung: Wir haben die Scans der Kleider genutzt, um sie digitalen Skeletten überzuziehen. Mit Hilfe einer „XBox 360 Kinect“ nehmen wir ein Tiefenbild der Umgebung auf. Damit können wir Position und Haltung des Nutzers bestimmen und so live das digitale 3D-Kleid mit dem realen Kamerabild des Nutzers verbinden. So entsteht der Eindruck, als trüge man das Kleid am eigenen Körper.
Die Bewegungsdaten des Nutzers nutzen wir zudem auch, um Gesten zuerkennen und so zuentscheiden, welches Kleid gerade getragen wird.
